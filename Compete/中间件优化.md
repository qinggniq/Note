# 中间件优化

## 初始化

- 空间尽量提早开辟，在Init的时候就开辟
- 初始化`map, slice`的时候需要设置合适的大小，避免slice在append的时候动态扩容
- 对于IO来说基本就是很快了，4.8G的数据1.3s就能拿到的样子，就dealWith的在wait状态的处理时间来说，基本就是计算跟不上IO了，简单的把parseLines移动到了IO线程，然后基本就优化了1s。接下来就是IO + （parseLine + filter）+ collect，让后面两个线程尽量同步？不过这个取决于处理速度吧，放到三个线程吧，但是速度快了之后backend跟不上的样子。

## 架构

- IO和计算并行，使用channel做同步，类似于生产者消费者模型
- IO线程发送速度尽量和消费（计算）速度相同，（这个在现在的代码里面没有做到）

## IO

- 避免使用bufio.Reader.ReadString，因为会涉及到多次的拷贝
  - kernel -> buffer	从内核读到bufio.Reader的buffer中
  - buffer -> []byte     Read的时候把buffer拷贝，然后返还给用户空间
  - []byte -> string     从[]byte（可变字符类型）到string（不可变字符类型）的拷贝
- 直接进行 raw io，自己parse content，这样就只有一次拷贝

## 计算

- 观察符合条件的span record的特征，使用trick的filter代码
- 使用*[零拷贝[]byte to string转型](https://github.com/golang/go/issues/25484)*
- 对于小数据，使用`slice.StableSort`，这样调用的是归并和插入排序，对小数据来说比快排更快
- 对于span record的startTime的比较，使用`bytes.Compare`代替`strconv.ParseInt`

## 杂项

- 评测机的调用顺序是client1 - client2 - backend，中间会间隔0.5s，所以可以通过`client1 -> backend -> client2` 来自定义的快速让3个机器启动。 （好像没啥用，即使是同步了，依然改变不了这个顺序，但是可以让client2在初始化buffer的时间变短（在使用init进行buffer的初始化之后就没有这个效果了），这样让setParameter的时间就会更快）
- 使用fasthttp甚至比使用gin效果更差，不知什么原因

## 架构 新的

如果按照徐师兄的用状态机来解析的话，那么可能确实更快一点，如果我维护一个buffer pool，输入是buffer，然后输出是

